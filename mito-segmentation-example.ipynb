{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd7c21a5-3ff9-46cb-b777-c85d91a8dc28",
   "metadata": {},
   "source": [
    "# Option 1: Just use neuprint\n",
    "\n",
    "After all, it gives you the volume of every mito..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fcb2d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samia/anaconda3/envs/torch_env/lib/python3.8/site-packages/neuprint/utils.py:62: UserWarning: \n",
      "Progress bar will not work well in the notebook without ipywidgets.\n",
      "Run the following commands (for notebook and jupyterlab users):\n",
      "\n",
      "    conda install -c conda-forge ipywidgets\n",
      "    jupyter nbextension enable --py widgetsnbextension\n",
      "    jupyter labextension install @jupyter-widgets/jupyterlab-manager\n",
      "\n",
      "...and then reload your jupyter session, and restart your kernel.\n",
      "\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# creds: Run this first\n",
    "NEUPRINT_APPLICATION_CREDENTIALS=\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJlbWFpbCI6InNtMjY2N0BjYW0uYWMudWsiLCJsZXZlbCI6Im5vYXV0aCIsImltYWdlLXVybCI6Imh0dHBzOi8vbGgzLmdvb2dsZXVzZXJjb250ZW50LmNvbS9hL0FDZzhvY0p2WTBzQURieG1OMW11OFAySldsb2Q4U296alpaajc3c1NJbG5RdXk1bD1zOTYtYz9zej01MD9zej01MCIsImV4cCI6MTg3NTc0Mzc3N30.oyY1HURafdq3mZAr1TU82M1Lr2TpG4q2HRB42LcnZ90\"\n",
    "from neuprint import Client, fetch_skeleton, fetch_mitochondria, skeleton_segments\n",
    "\n",
    "client = Client('neuprint.janelia.org', 'hemibrain:v1.2.1', token=NEUPRINT_APPLICATION_CREDENTIALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef6584b1-fb6d-449c-b094-740cf54bc0cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for |=: 'dict' and 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m body \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5813020698\u001b[39m\n\u001b[1;32m      2\u001b[0m skeleton \u001b[38;5;241m=\u001b[39m fetch_skeleton(body)\n\u001b[0;32m----> 3\u001b[0m mitos \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_mitochondria\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull skeleton has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(skeleton)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m nodes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull neuron has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(mitos)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m mitochondria\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.8/site-packages/neuprint/client.py:240\u001b[0m, in \u001b[0;36minject_client.<locals>.wrapper\u001b[0;34m(client, *args, **kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m client \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    239\u001b[0m     client \u001b[38;5;241m=\u001b[39m default_client()\n\u001b[0;32m--> 240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.8/site-packages/neuprint/queries/neuroncriteria.py:36\u001b[0m, in \u001b[0;36mneuroncriteria_args.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m argnames:\n\u001b[1;32m     35\u001b[0m     callargs[name] \u001b[38;5;241m=\u001b[39m copy_as_neuroncriteria(callargs[name], callargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclient\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcallargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.8/site-packages/neuprint/queries/mito.py:90\u001b[0m, in \u001b[0;36mfetch_mitochondria\u001b[0;34m(neuron_criteria, mito_criteria, batch_size, client)\u001b[0m\n\u001b[1;32m     84\u001b[0m mito_criteria\u001b[38;5;241m.\u001b[39mmatchvar \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     85\u001b[0m neuron_criteria\u001b[38;5;241m.\u001b[39mmatchvar \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     87\u001b[0m q \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mneuron_criteria\u001b[38;5;241m.\u001b[39mglobal_with(prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;124m    MATCH (n:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mneuron_criteria\u001b[38;5;241m.\u001b[39mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\n\u001b[0;32m---> 90\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mneuron_criteria\u001b[38;5;241m.\u001b[39mall_conditions(prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124m    RETURN n.bodyId as bodyId\u001b[39m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     93\u001b[0m bodies \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mfetch_custom(q)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbodyId\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m     95\u001b[0m batch_dfs \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.8/site-packages/neuprint/queries/neuroncriteria.py:855\u001b[0m, in \u001b[0;36mNeuronCriteria.all_conditions\u001b[0;34m(self, prefix, comments, *vars)\u001b[0m\n\u001b[1;32m    852\u001b[0m \u001b[38;5;28mvars\u001b[39m \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mvars\u001b[39m} \u001b[38;5;241m|\u001b[39m {\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmatchvar, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglobal_vars()\u001b[38;5;241m.\u001b[39mkeys()}\n\u001b[1;32m    853\u001b[0m \u001b[38;5;28mvars\u001b[39m \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mvars\u001b[39m,)\n\u001b[0;32m--> 855\u001b[0m basic_cond \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbasic_conditions\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomments\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m basic_cond:\n\u001b[1;32m    857\u001b[0m     basic_cond \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWHERE \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mbasic_cond\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.8/site-packages/neuprint/queries/neuroncriteria.py:926\u001b[0m, in \u001b[0;36mNeuronCriteria.basic_conditions\u001b[0;34m(self, prefix, comments)\u001b[0m\n\u001b[1;32m    921\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbasic_conditions\u001b[39m(\u001b[38;5;28mself\u001b[39m, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, comments\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    922\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;124;03m    Construct a WHERE clause based on the basic conditions\u001b[39;00m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;124;03m    in this criteria (i.e. everything except for the \"directed ROI\" conditions.)\u001b[39;00m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m     exprs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbasic_exprs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    927\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exprs:\n\u001b[1;32m    928\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.8/site-packages/neuprint/queries/neuroncriteria.py:729\u001b[0m, in \u001b[0;36mNeuronCriteria.basic_exprs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    726\u001b[0m     exprs[(prop,)] \u001b[38;5;241m=\u001b[39m expr\n\u001b[1;32m    728\u001b[0m \u001b[38;5;66;03m# These are other types of expressions.\u001b[39;00m\n\u001b[0;32m--> 729\u001b[0m exprs \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    730\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstance\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregex\u001b[39m\u001b[38;5;124m'\u001b[39m): \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtypeinst_expr(),\n\u001b[1;32m    731\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcropped\u001b[39m\u001b[38;5;124m'\u001b[39m,): \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tag_expr(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcropped\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcropped),\n\u001b[1;32m    732\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msomaLocation\u001b[39m\u001b[38;5;124m'\u001b[39m,): \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nullcheck_expr(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msomaLocation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msomaLocation),\n\u001b[1;32m    733\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtosomaLocation\u001b[39m\u001b[38;5;124m'\u001b[39m,): \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nullcheck_expr(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtosomaLocation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtosomaLocation),\n\u001b[1;32m    734\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrootLocation\u001b[39m\u001b[38;5;124m'\u001b[39m,): \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nullcheck_expr(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrootLocation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrootLocation),\n\u001b[1;32m    735\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoma\u001b[39m\u001b[38;5;124m'\u001b[39m,): \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_single_value_expr(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msomaLocation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msoma),  \u001b[38;5;66;03m# deprecated arg\u001b[39;00m\n\u001b[1;32m    736\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_pre\u001b[39m\u001b[38;5;124m'\u001b[39m,): \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gt_eq_expr(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpre\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_pre),\n\u001b[1;32m    737\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_post\u001b[39m\u001b[38;5;124m'\u001b[39m,): \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gt_eq_expr(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_post),\n\u001b[1;32m    738\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrois\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minputRois\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutputRois\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroi_req\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_roi_inputs\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_roi_outputs\u001b[39m\u001b[38;5;124m'\u001b[39m): \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrois_expr(),\n\u001b[1;32m    739\u001b[0m     \u001b[38;5;66;03m# No expression for label;\u001b[39;00m\n\u001b[1;32m    740\u001b[0m     \u001b[38;5;66;03m# enclosing queries are responsible for inserting label into their MATCH statement.\u001b[39;00m\n\u001b[1;32m    741\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m,): \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    742\u001b[0m }\n\u001b[1;32m    744\u001b[0m \u001b[38;5;66;03m# Since we've got a lot of criteria to generate expressions for,\u001b[39;00m\n\u001b[1;32m    745\u001b[0m \u001b[38;5;66;03m# let's verify that we remembered to implement expressions for every\u001b[39;00m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;66;03m# argument in the NeuronCriteria constructor.\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPYTEST_CURRENT_TEST\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for |=: 'dict' and 'dict'"
     ]
    }
   ],
   "source": [
    "body = 5813020698\n",
    "skeleton = fetch_skeleton(body)\n",
    "mitos = fetch_mitochondria(body)\n",
    "print(f\"Full skeleton has {len(skeleton)} nodes\")\n",
    "print(f\"Full neuron has {len(mitos)} mitochondria\")\n",
    "\n",
    "# Define a box encompassing a big section of the FB, just for the sake of this example.\n",
    "# This isn't the whole, FB, I just chose an arbitrary portion of it.\n",
    "corner_0 = (29899, 21349, 14841)\n",
    "corner_1 = (33508, 25741, 19111)\n",
    "branch_box = np.array((corner_0, corner_1))\n",
    "\n",
    "skel_coords = skeleton[['x', 'y', 'z']].values\n",
    "trimmed_skeleton = skeleton.loc[(skel_coords >= corner_0) & (skel_coords < corner_1)]\n",
    "\n",
    "mito_coords = mitos[['x', 'y', 'z']].values\n",
    "filtered_mitos = mitos.loc[(mito_coords >= corner_0) & (mito_coords < corner_1)]\n",
    "\n",
    "print('---')\n",
    "print(f\"Trimmed skeleton has {len(trimmed_skeleton)} nodes\")\n",
    "print(f\"Selected {len(filtered_mitos)} mitochondria\")\n",
    "\n",
    "# Estimate the neuron volume by calculating the volume of each skeleton segment\n",
    "# (interpolating between the radii of each skeleton node).\n",
    "# This is not as accurate as using the real voxelwise segmentation, but might be good enough.\n",
    "segments = skeleton_segments(trimmed_skeleton)\n",
    "mito_frac = filtered_mitos['size'].sum() / segments['volume'].sum()\n",
    "print('---')\n",
    "print(f'Mitos occupy about {100*mito_frac:.0f}% of the selected volume')\n",
    "\n",
    "# NOTE: The mito volume is listed in VOXEL units (8nm^3).\n",
    "# To convert to cubic microns, you need to convert units.\n",
    "cubic_nm_per_voxel = 8**3  # cubic nanometers\n",
    "cubic_um_per_voxel = cubic_nm_per_voxel / (1000**3)  # cubic micrometers\n",
    "\n",
    "trimmed_segment_vol_cubic_um = segments['volume'].sum() * cubic_um_per_voxel\n",
    "filtered_mito_vol_cubic_um = filtered_mitos['size'].sum() * cubic_um_per_voxel\n",
    "print('---')\n",
    "print(f\"Trimmed skeleton occupies {trimmed_segment_vol_cubic_um:.1f} cubic microns\")\n",
    "print(f\"Select mitos occupy {filtered_mito_vol_cubic_um:.1f} cubic microns in total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5d97ba-889d-48e3-8e81-7103feb2dade",
   "metadata": {},
   "source": [
    "# Option 2: Download cropped subvolumes of the neuron/mito segmentations.\n",
    "\n",
    "BTW, Here's the standard hemibrain neuroglancer view:<br>\n",
    "https://neuroglancer-demo.appspot.com/#!gs://flyem-views/hemibrain/v1.2/base.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "698c94f2-f8f4-4304-a207-5b787a04901b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tensorstore\n",
    "import tensorstore as ts\n",
    "import numpy as np\n",
    "\n",
    "# Adapted from the TensorStore tutorial:\n",
    "# https://google.github.io/tensorstore/python/tutorial.html#reading-the-janelia-flyem-hemibrain-dataset\n",
    "dataset_future = ts.open({\n",
    "    'driver':\n",
    "        'neuroglancer_precomputed',\n",
    "    'kvstore':\n",
    "        'gs://neuroglancer-janelia-flyem-hemibrain/v1.1/segmentation/',\n",
    "    # Use 100MB in-memory cache.\n",
    "    'context': {\n",
    "        'cache_pool': {\n",
    "            'total_bytes_limit': 100_000_000\n",
    "        }\n",
    "    },\n",
    "    'recheck_cached_data':\n",
    "        'open',\n",
    "})\n",
    "\n",
    "neuron_dset = dataset_future.result()[ts.d['channel'][0]]\n",
    "\n",
    "mito_future = ts.open({\n",
    "    'driver':\n",
    "        'neuroglancer_precomputed',\n",
    "    'kvstore':\n",
    "        'gs://neuroglancer-janelia-flyem-hemibrain/v1.2/mito-objects',  # individual mito\n",
    "        #'gs://neuroglancer-janelia-flyem-hemibrain/v1.2/mito-objects-grouped',  # grouped mito, where they all match their parent neuron\n",
    "    # Use 100MB in-memory cache.\n",
    "    'context': {\n",
    "        'cache_pool': {\n",
    "            'total_bytes_limit': 100_000_000\n",
    "        }\n",
    "    },\n",
    "    'recheck_cached_data':\n",
    "        'open',\n",
    "})\n",
    "\n",
    "mito_dset = mito_future.result()[ts.d['channel'][0]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c192232-d4fd-4838-b574-164dcee650f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a central coordinate and define a window (box) around it.\n",
    "c = np.array([32928, 25014, 18282])\n",
    "box = np.array([c - 100, c + 100])\n",
    "[(x,y,z), (X,Y,Z)] = box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768d0f21-346e-4b0e-8d41-dce4c15c3831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a thin 2D slice, shrink the z:Z region\n",
    "# z, Z = (c[2], c[2]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "008cb40f-cdcb-4034-bdec-615df368d9f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 200, 200)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch cubes of segmentation from neuron segmentation and mito segmentation\n",
    "neuron_vol = neuron_dset[x:X, y:Y, z:Z].read().result()\n",
    "mito_vol = mito_dset[x:X, y:Y, z:Z].read().result()\n",
    "neuron_vol.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdce2141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(7550, 10503, 18210), (9874, 11859, 18510)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1709290226.226147 3892903 gcs_resource.cc:99] Using default AdmissionQueue with limit 32\n",
      "W0000 00:00:1709290226.230387 3895201 curl_transport.cc:431] Error [6]=Couldn't resolve host name in curl operation\n",
      "Could not resolve host: metadata.google.internal\n",
      "E0000 00:00:1709290226.230431 3895202 google_auth_provider.cc:186] Could not find the credentials file in the standard gcloud location [/home/samia/.config/gcloud/application_default_credentials.json]. You may specify a credentials file using $GOOGLE_APPLICATION_CREDENTIALS, or to use Google application default credentials, run: gcloud auth application-default login\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking dtypes to see if conversion is need or not!\n",
      "EM vol uint8, EM vol CLAHE uint8,      Soma labels uint64, Mito labels uint64\n"
     ]
    }
   ],
   "source": [
    "# Fetch Somas, EM raw, Mito\n",
    "# NB: Labels have errors \n",
    "\n",
    "import tensorstore as ts\n",
    "import numpy as np\n",
    "import zarr\n",
    "\n",
    "# # specify the central coordinates\n",
    "# c_x = 19676\n",
    "# c_y = 12227\n",
    "# c_z = 13244\n",
    "\n",
    "# boundingBox 1\n",
    "x1= 7550\n",
    "x2= 9875\n",
    "y1=10503\n",
    "y2=11860\n",
    "z1=18210\n",
    "z2=18510\n",
    "\n",
    "dif_x = (x2-x1) // 2\n",
    "dif_y = (y2-y1) // 2\n",
    "dif_z = (z2-z1) // 2\n",
    "c_x= dif_x + x1  \n",
    "c_y= dif_y + y1 \n",
    "c_z = dif_z + z1 \n",
    "\n",
    "# boundingBox 2\n",
    "# x1= 5290\n",
    "# x2= 6479\n",
    "# y1=11612\n",
    "# y2=12835\n",
    "# z1=18100\n",
    "# z2=18350\n",
    "\n",
    "# dif_x = (x2-x1) // 2\n",
    "# dif_y = (y2-y1) // 2\n",
    "# dif_z = (z2-z1) // 2\n",
    "# c_x= dif_x + x1  \n",
    "# c_y= dif_y + y1 \n",
    "# c_z = dif_z + z1 \n",
    "\n",
    "# boundingBox 3\n",
    "# x1= 6404\n",
    "# x2= 8415\n",
    "# y1=11500\n",
    "# y2=13058\n",
    "# z1=18035\n",
    "# z2=18235\n",
    "\n",
    "# dif_x = (x2-x1) // 2\n",
    "# dif_y = (y2-y1) // 2\n",
    "# dif_z = (z2-z1) // 2\n",
    "# c_x= dif_x + x1  \n",
    "# c_y= dif_y + y1 \n",
    "# c_z = dif_z + z1 \n",
    "\n",
    "\n",
    "\n",
    "# calculate the Roi bounding box\n",
    "c = np.array([c_x, c_y, c_z])\n",
    "box =  np.array([c[0] - dif_x, c[0]+dif_x, c[1]-dif_y, c[1]+dif_y, c[2]-dif_z,c[2]+dif_z])\n",
    "# box = np.array([c - 256, c + 256]) # shape 512 x 512 x 512\n",
    "# print(box)\n",
    "\n",
    "# [(x,y,z), (X,Y,Z)] = box\n",
    "\n",
    "x,y,z= box[0], box[2], box[4]\n",
    "X, Y, Z = box[1], box[3], box[5]\n",
    "\n",
    "print([(x,y,z), (X,Y,Z)])\n",
    "\n",
    "# Adapted from the TensorStore tutorial:\n",
    "# https://google.github.io/tensorstore/python/tutorial.html#reading-the-janelia-flyem-hemibrain-dataset\n",
    "soma_dataset_future = ts.open({\n",
    "    'driver':\n",
    "        'neuroglancer_precomputed',\n",
    "    'kvstore':\n",
    "        'gs://neuroglancer-janelia-flyem-hemibrain/v1.1/segmentation/',\n",
    "    # Use 100MB in-memory cache.\n",
    "    'context': {\n",
    "        'cache_pool': {\n",
    "            'total_bytes_limit': 100_000_000\n",
    "        }\n",
    "    },\n",
    "    'recheck_cached_data':\n",
    "        'open',\n",
    "})\n",
    "\n",
    "# raw EM non-CLAHE?\n",
    "em_dataset_future = ts.open({\n",
    "    'driver':\n",
    "        'neuroglancer_precomputed',\n",
    "    'kvstore':\n",
    "        'gs://neuroglancer-janelia-flyem-hemibrain/emdata/raw/jpeg',\n",
    "    # Use 100MB in-memory cache.\n",
    "    'context': {\n",
    "        'cache_pool': {\n",
    "            'total_bytes_limit': 100_000_000\n",
    "        }\n",
    "    },\n",
    "    'recheck_cached_data':\n",
    "        'open',\n",
    "})\n",
    "\n",
    "# CLAHE in YZ\n",
    "\n",
    "em_clahe_dataset_future = ts.open({\n",
    "    'driver':\n",
    "        'neuroglancer_precomputed',\n",
    "    'kvstore':\n",
    "        'gs://neuroglancer-janelia-flyem-hemibrain/emdata/clahe_yz/jpeg',\n",
    "    # Use 100MB in-memory cache.\n",
    "    'context': {\n",
    "        'cache_pool': {\n",
    "            'total_bytes_limit': 100_000_000\n",
    "        }\n",
    "    },\n",
    "    'recheck_cached_data':\n",
    "        'open',\n",
    "})\n",
    "\n",
    "# mitochondria -nndividual\n",
    "mito_future = ts.open({\n",
    "    'driver':\n",
    "        'neuroglancer_precomputed',\n",
    "    'kvstore':\n",
    "        'gs://neuroglancer-janelia-flyem-hemibrain/v1.2/mito-objects',  # individual mito\n",
    "        #'gs://neuroglancer-janelia-flyem-hemibrain/v1.2/mito-objects-grouped',  # grouped mito, where they all match their parent neuron\n",
    "    # Use 100MB in-memory cache.\n",
    "    'context': {\n",
    "        'cache_pool': {\n",
    "            'total_bytes_limit': 100_000_000\n",
    "        }\n",
    "    },\n",
    "    'recheck_cached_data':\n",
    "        'open',\n",
    "})\n",
    "# mitochondria -grouped, matched to parent neuron - donno what this means exactly??\n",
    "\n",
    "mito_grp_future = ts.open({\n",
    "    'driver':\n",
    "        'neuroglancer_precomputed',\n",
    "    'kvstore':\n",
    "#         'gs://neuroglancer-janelia-flyem-hemibrain/v1.2/mito-objects',  # individual mito\n",
    "        'gs://neuroglancer-janelia-flyem-hemibrain/v1.2/mito-objects-grouped',  # grouped mito, where they all match their parent neuron\n",
    "    # Use 100MB in-memory cache.\n",
    "    'context': {\n",
    "        'cache_pool': {\n",
    "            'total_bytes_limit': 100_000_000\n",
    "        }\n",
    "    },\n",
    "    'recheck_cached_data':\n",
    "        'open',\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "# all arrays should be in XYZ orientation, however we want them to have ZYX for compatibility with existing code\n",
    "\n",
    "soma_dset = soma_dataset_future.result()[ts.d['channel'][0]] # strip the channel dim as it is \"1\": grayscale\n",
    "soma_vol = np.transpose(soma_dset[x:X, y:Y, z:Z].read().result(), (2,1,0))\n",
    "\n",
    "em_dset = em_dataset_future.result()[ts.d['channel'][0]]\n",
    "em_vol = np.transpose(em_dset[x:X, y:Y, z:Z].read().result(), (2,1,0))\n",
    "\n",
    "em_clahe_dset = em_clahe_dataset_future.result()[ts.d['channel'][0]]\n",
    "em_clahe_vol = np.transpose(em_clahe_dset[x:X, y:Y, z:Z].read().result(), (2,1,0))\n",
    "\n",
    "mito_dset = mito_future.result()[ts.d['channel'][0]]\n",
    "mito_vol = np.transpose(mito_dset[x:X, y:Y, z:Z].read().result(), (2,1,0))\n",
    "\n",
    "mito_grp_dset = mito_grp_future.result()[ts.d['channel'][0]]\n",
    "mito_grp_vol = np.transpose(mito_dset[x:X, y:Y, z:Z].read().result(), (2,1,0))\n",
    "\n",
    "\n",
    "# FIX ME: We do not do transform the data dtypes before saving as zarr datasets, but good to know\n",
    "print(\"Checking dtypes to see if conversion is need or not!\")\n",
    "print(f\"EM vol {em_vol.dtype}, EM vol CLAHE {em_clahe_vol.dtype},\\\n",
    "      Soma labels {soma_vol.dtype}, Mito labels {mito_vol.dtype}\")\n",
    "\n",
    "# we check that the Roi has tissue data is not empty\n",
    "countzero = not np.all(em_vol)\n",
    "assert countzero, \"Raw is empty\"\n",
    "\n",
    "f = zarr.open(f\"/media/samia/DATA/ark/dan-samia/lsd/funke/hemi/mito/hemi_x{c_x}_y{c_y}_z{c_z}.zarr\", \"a\")\n",
    "# these are somas but we call them neuronids since they are essentially that. Also, helps maintain consistency!\n",
    "f[\"volumes/labels/neuron_ids\"] = soma_vol # potentially uint64\n",
    "f[\"volumes/labels/neuron_ids\"].attrs[\"offset\"] = (0,0,0)\n",
    "f[\"volumes/labels/neuron_ids\"].attrs[\"resolution\"] = (8,8,8)\n",
    "f[\"volumes/labels/neuron_ids\"].attrs[\"crop_central_coords_xyz\"] = (c_x, c_y, c_z)\n",
    "\n",
    "f[\"volumes/raw\"] = em_vol # potentially uint8\n",
    "f[\"volumes/raw\"].attrs[\"offset\"] = (0,0,0)\n",
    "f[\"volumes/raw\"].attrs[\"resolution\"] = (8,8,8)\n",
    "f[\"volumes/raw\"].attrs[\"crop_central_coords_xyz\"] = (c_x, c_y, c_z)\n",
    "\n",
    "f[\"volumes/raw_clahe\"] = em_clahe_vol # potentially uint8\n",
    "f[\"volumes/raw_clahe\"].attrs[\"offset\"] = (0,0,0)\n",
    "f[\"volumes/raw_clahe\"].attrs[\"resolution\"] = (8,8,8)\n",
    "f[\"volumes/raw_clahe\"].attrs[\"crop_central_coords_xyz\"] = (c_x, c_y, c_z)\n",
    "\n",
    "f[\"volumes/raw_clahe\"] = em_clahe_vol # potentially uint8\n",
    "f[\"volumes/raw_clahe\"].attrs[\"offset\"] = (0,0,0)\n",
    "f[\"volumes/raw_clahe\"].attrs[\"resolution\"] = (8,8,8)\n",
    "f[\"volumes/raw_clahe\"].attrs[\"crop_central_coords_xyz\"] = (c_x, c_y, c_z)\n",
    "\n",
    "f[\"volumes/labels/mito_ids\"] = mito_vol # potentially uint64\n",
    "f[\"volumes/labels/mito_ids\"].attrs[\"offset\"] = (0,0,0)\n",
    "f[\"volumes/labels/mito_ids\"].attrs[\"resolution\"] = (8,8,8)\n",
    "f[\"volumes/labels/mito_ids\"].attrs[\"crop_central_coords_xyz\"] = (c_x, c_y, c_z)\n",
    "\n",
    "f[\"volumes/labels/mito_grp_ids\"] = mito_grp_vol # potentially uint64\n",
    "f[\"volumes/labels/mito_grp_ids\"].attrs[\"offset\"] = (0,0,0)\n",
    "f[\"volumes/labels/mito_grp_ids\"].attrs[\"resolution\"] = (8,8,8)\n",
    "f[\"volumes/labels/mito_grp_ids\"].attrs[\"crop_central_coords_xyz\"] = (c_x, c_y, c_z)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a38127e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorstore as ts\n",
    "import numpy as np\n",
    "import zarr\n",
    "\n",
    "# Adapted from the TensorStore tutorial:\n",
    "# https://google.github.io/tensorstore/python/tutorial.html#reading-the-janelia-flyem-hemibrain-dataset\n",
    "soma_dataset_future = ts.open({\n",
    "    'driver':\n",
    "        'neuroglancer_precomputed',\n",
    "    'kvstore':\n",
    "        'gs://neuroglancer-janelia-flyem-hemibrain/v1.1/segmentation/',\n",
    "    # Use 100MB in-memory cache.\n",
    "    'context': {\n",
    "        'cache_pool': {\n",
    "            'total_bytes_limit': 100_000_000\n",
    "        }\n",
    "    },\n",
    "    'recheck_cached_data':\n",
    "        'open',\n",
    "})\n",
    "\n",
    "# raw EM non-CLAHE?\n",
    "em_dataset_future = ts.open({\n",
    "    'driver':\n",
    "        'neuroglancer_precomputed',\n",
    "    'kvstore':\n",
    "        'gs://neuroglancer-janelia-flyem-hemibrain/emdata/raw/jpeg',\n",
    "    # Use 100MB in-memory cache.\n",
    "    'context': {\n",
    "        'cache_pool': {\n",
    "            'total_bytes_limit': 100_000_000\n",
    "        }\n",
    "    },\n",
    "    'recheck_cached_data':\n",
    "        'open',\n",
    "})\n",
    "\n",
    "# CLAHE in YZ\n",
    "\n",
    "em_clahe_dataset_future = ts.open({\n",
    "    'driver':\n",
    "        'neuroglancer_precomputed',\n",
    "    'kvstore':\n",
    "        'gs://neuroglancer-janelia-flyem-hemibrain/emdata/clahe_yz/jpeg',\n",
    "    # Use 100MB in-memory cache.\n",
    "    'context': {\n",
    "        'cache_pool': {\n",
    "            'total_bytes_limit': 100_000_000\n",
    "        }\n",
    "    },\n",
    "    'recheck_cached_data':\n",
    "        'open',\n",
    "})\n",
    "\n",
    "# mitochondria -nndividual\n",
    "mito_future = ts.open({\n",
    "    'driver':\n",
    "        'neuroglancer_precomputed',\n",
    "    'kvstore':\n",
    "        'gs://neuroglancer-janelia-flyem-hemibrain/v1.2/mito-objects',  # individual mito\n",
    "        #'gs://neuroglancer-janelia-flyem-hemibrain/v1.2/mito-objects-grouped',  # grouped mito, where they all match their parent neuron\n",
    "    # Use 100MB in-memory cache.\n",
    "    'context': {\n",
    "        'cache_pool': {\n",
    "            'total_bytes_limit': 100_000_000\n",
    "        }\n",
    "    },\n",
    "    'recheck_cached_data':\n",
    "        'open',\n",
    "})\n",
    "# mitochondria -grouped, matched to parent neuron - donno what this means exactly??\n",
    "\n",
    "mito_grp_future = ts.open({\n",
    "    'driver':\n",
    "        'neuroglancer_precomputed',\n",
    "    'kvstore':\n",
    "#         'gs://neuroglancer-janelia-flyem-hemibrain/v1.2/mito-objects',  # individual mito\n",
    "        'gs://neuroglancer-janelia-flyem-hemibrain/v1.2/mito-objects-grouped',  # grouped mito, where they all match their parent neuron\n",
    "    # Use 100MB in-memory cache.\n",
    "    'context': {\n",
    "        'cache_pool': {\n",
    "            'total_bytes_limit': 100_000_000\n",
    "        }\n",
    "    },\n",
    "    'recheck_cached_data':\n",
    "        'open',\n",
    "})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf375aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking dtypes to see if conversion is need or not!\n",
      "EM vol uint8, EM vol CLAHE uint8,              Soma labels uint64, Mito labels uint64\n",
      "/media/samia/DATA/ark/dan-samia/lsd/funke/hemi/mito/hemi_x9687_y20286_z15713.zarr saved here!\n",
      "Changing directions\n",
      "Checking dtypes to see if conversion is need or not!\n",
      "EM vol uint8, EM vol CLAHE uint8,              Soma labels uint64, Mito labels uint64\n",
      "/media/samia/DATA/ark/dan-samia/lsd/funke/hemi/mito/hemi_x8663_y20286_z15713.zarr saved here!\n"
     ]
    }
   ],
   "source": [
    "num_rois = 2\n",
    "\n",
    "# specify the central coordinates\n",
    "c_x = 9175 \n",
    "c_y = 20286 \n",
    "c_z = 15713\n",
    "\n",
    "# make a copy of the central coords such that you don't lose them, will help in changing cropping directions\n",
    "\n",
    "cc_x = c_x\n",
    "cc_y = c_y\n",
    "cc_z = c_z\n",
    "change_dir= False # change direction\n",
    "\n",
    "for i in range(num_rois):\n",
    "    \n",
    "    # hope loop continues even when errors\n",
    "    try:\n",
    "        # calculate the Roi bounding box\n",
    "        c = np.array([c_x, c_y, c_z])\n",
    "        box = np.array([c - 256, c + 256]) # shape 512 x 512 x 512\n",
    "        [(x,y,z), (X,Y,Z)] = box\n",
    "\n",
    "        # update the central coordinates based on where you want to cut the next roi from\n",
    "        # using 512 shifts in y direction (up-down) for now, x and z remain same\n",
    "        # Sorry.. hard-coded direction change for now!!\n",
    "        if i == num_rois//2:\n",
    "            # change directions\n",
    "            print(\"Changing directions\")\n",
    "\n",
    "            change_dir = True\n",
    "            # reset the central coord \n",
    "            c_x = cc_x\n",
    "        \n",
    "        if change_dir:\n",
    "            c_x -= 512 # start cropping upwards\n",
    "        else:\n",
    "            c_x += 512 # start cropping upwards\n",
    "\n",
    "        # all arrays should be in XYZ orientation, however we want them to have ZYX for compatibility with existing code\n",
    "\n",
    "        soma_dset = soma_dataset_future.result()[ts.d['channel'][0]] # strip the channel dim as it is \"1\": grayscale\n",
    "        soma_vol = np.transpose(soma_dset[x:X, y:Y, z:Z].read().result(), (2,1,0))\n",
    "\n",
    "        em_dset = em_dataset_future.result()[ts.d['channel'][0]]\n",
    "        em_vol = np.transpose(em_dset[x:X, y:Y, z:Z].read().result(), (2,1,0))\n",
    "\n",
    "        em_clahe_dset = em_clahe_dataset_future.result()[ts.d['channel'][0]]\n",
    "        em_clahe_vol = np.transpose(em_clahe_dset[x:X, y:Y, z:Z].read().result(), (2,1,0))\n",
    "\n",
    "        mito_dset = mito_future.result()[ts.d['channel'][0]]\n",
    "        mito_vol = np.transpose(mito_dset[x:X, y:Y, z:Z].read().result(), (2,1,0))\n",
    "\n",
    "        mito_grp_dset = mito_grp_future.result()[ts.d['channel'][0]]\n",
    "        mito_grp_vol = np.transpose(mito_dset[x:X, y:Y, z:Z].read().result(), (2,1,0))\n",
    "\n",
    "\n",
    "        # FIX ME: We do not do transform the data dtypes before saving as zarr datasets, but good to know\n",
    "        print(\"Checking dtypes to see if conversion is need or not!\")\n",
    "        print(f\"EM vol {em_vol.dtype}, EM vol CLAHE {em_clahe_vol.dtype},\\\n",
    "              Soma labels {soma_vol.dtype}, Mito labels {mito_vol.dtype}\")\n",
    "\n",
    "        # check that the Roi has tissue data is not empty\n",
    "        countzero = not np.all(em_vol)\n",
    "        assert countzero, \"Raw is empty\"\n",
    "        \n",
    "        outfile= f\"/media/samia/DATA/ark/dan-samia/lsd/funke/hemi/mito/hemi_x{c_x}_y{c_y}_z{c_z}.zarr\" \n",
    "\n",
    "        f = zarr.open(outfile, \"a\")\n",
    "        # these are somas but we call them neuronids since they are essentially that. Also, help maintain consistency!\n",
    "        f[\"volumes/labels/neuron_ids\"] = soma_vol # potentially uint64\n",
    "        f[\"volumes/labels/neuron_ids\"].attrs[\"offset\"] = (0,0,0)\n",
    "        f[\"volumes/labels/neuron_ids\"].attrs[\"resolution\"] = (8,8,8)\n",
    "        f[\"volumes/labels/neuron_ids\"].attrs[\"crop_central_coords_xyz\"] = (c_x, c_y, c_z)\n",
    "\n",
    "        f[\"volumes/raw\"] = em_vol # potentially uint8\n",
    "        f[\"volumes/raw\"].attrs[\"offset\"] = (0,0,0)\n",
    "        f[\"volumes/raw\"].attrs[\"resolution\"] = (8,8,8)\n",
    "        f[\"volumes/raw\"].attrs[\"crop_central_coords_xyz\"] = (c_x, c_y, c_z)\n",
    "\n",
    "        f[\"volumes/raw_clahe\"] = em_clahe_vol # potentially uint8\n",
    "        f[\"volumes/raw_clahe\"].attrs[\"offset\"] = (0,0,0)\n",
    "        f[\"volumes/raw_clahe\"].attrs[\"resolution\"] = (8,8,8)\n",
    "        f[\"volumes/raw_clahe\"].attrs[\"crop_central_coords_xyz\"] = (c_x, c_y, c_z)\n",
    "\n",
    "        f[\"volumes/raw_clahe\"] = em_clahe_vol # potentially uint8\n",
    "        f[\"volumes/raw_clahe\"].attrs[\"offset\"] = (0,0,0)\n",
    "        f[\"volumes/raw_clahe\"].attrs[\"resolution\"] = (8,8,8)\n",
    "        f[\"volumes/raw_clahe\"].attrs[\"crop_central_coords_xyz\"] = (c_x, c_y, c_z)\n",
    "\n",
    "        f[\"volumes/labels/mito_ids\"] = mito_vol # potentially uint64\n",
    "        f[\"volumes/labels/mito_ids\"].attrs[\"offset\"] = (0,0,0)\n",
    "        f[\"volumes/labels/mito_ids\"].attrs[\"resolution\"] = (8,8,8)\n",
    "        f[\"volumes/labels/mito_ids\"].attrs[\"crop_central_coords_xyz\"] = (c_x, c_y, c_z)\n",
    "\n",
    "        f[\"volumes/labels/mito_grp_ids\"] = mito_grp_vol # potentially uint64\n",
    "        f[\"volumes/labels/mito_grp_ids\"].attrs[\"offset\"] = (0,0,0)\n",
    "        f[\"volumes/labels/mito_grp_ids\"].attrs[\"resolution\"] = (8,8,8)\n",
    "        f[\"volumes/labels/mito_grp_ids\"].attrs[\"crop_central_coords_xyz\"] = (c_x, c_y, c_z)\n",
    "        \n",
    "        print(f\"{outfile} saved here!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c71b0207-5a6c-4dfa-8203-bb6fd37e7321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero out the parts of mito_vol that don't belong to our neuron of interest\n",
    "body = 5813020698\n",
    "neuron_mask = (neuron_vol == body)\n",
    "mito_vol = np.where(neuron_mask, mito_vol, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0f7362f-f5a0-4afd-b542-e4eb5ca0a1e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48834567916092503"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What fraction does the mito occupy?\n",
    "(mito_vol != 0).sum() / neuron_mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c61d21c-911c-4ee8-8a27-e361ceb74057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             7675381\n",
       "7191815110     324107\n",
       "7191814327        324\n",
       "7191815883        188\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here's a quick way to see what mito IDs we have in our little volume and how many there are.\n",
    "# Note that we accidentally captured tiny slivers of mito from neighboring neurons.\n",
    "# You may want to discard those.\n",
    "import pandas as pd\n",
    "pd.value_counts(mito_vol.flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb2f488-7941-4aae-902b-91f7e4d9ac64",
   "metadata": {},
   "source": [
    "# Extra Credit: Use the Neuroglancer Python API to help you visualize what's going on\n",
    "\n",
    "The neuroglancer Javascript viewer has a companion Python package. If you create a `Viewer` with the Python API, you can use Python commands to \"remote control\" the viewer (position, object selection, etc.).  But you can ALSO use it to visualize your own numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c7cef99-b68a-407c-8f7e-2af1dcaf051a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is just a view of the hemibrain\n",
    "TEMPLATE_LINK = 'https://neuroglancer-demo.appspot.com/#!%7B%22dimensions%22:%7B%22x%22:%5B8e-9%2C%22m%22%5D%2C%22y%22:%5B8e-9%2C%22m%22%5D%2C%22z%22:%5B8e-9%2C%22m%22%5D%7D%2C%22position%22:%5B15807.5%2C21274.5%2C18124.5%5D%2C%22crossSectionScale%22:54.37327962468417%2C%22crossSectionDepth%22:-37.62185354999912%2C%22projectionScale%22:109219.18067006872%2C%22layers%22:%5B%7B%22type%22:%22image%22%2C%22source%22:%22precomputed://gs://neuroglancer-janelia-flyem-hemibrain/emdata/clahe_yz/jpeg%22%2C%22tab%22:%22source%22%2C%22name%22:%22emdata%22%7D%2C%7B%22type%22:%22segmentation%22%2C%22source%22:%7B%22url%22:%22precomputed://gs://neuroglancer-janelia-flyem-hemibrain/v1.2/segmentation%22%2C%22subsources%22:%7B%22default%22:true%2C%22properties%22:true%2C%22mesh%22:true%7D%2C%22enableDefaultSubsources%22:false%7D%2C%22tab%22:%22segments%22%2C%22objectAlpha%22:0.3%2C%22segments%22:%5B%5D%2C%22name%22:%22segmentation%22%7D%2C%7B%22type%22:%22segmentation%22%2C%22source%22:%7B%22url%22:%22precomputed://gs://neuroglancer-janelia-flyem-hemibrain/v1.2/mito-objects-grouped%22%2C%22subsources%22:%7B%22default%22:true%2C%22mesh%22:true%7D%2C%22enableDefaultSubsources%22:false%7D%2C%22pick%22:false%2C%22tab%22:%22segments%22%2C%22selectedAlpha%22:0%2C%22saturation%22:0%2C%22linkedSegmentationGroup%22:%22segmentation%22%2C%22name%22:%22mito-grouped%22%7D%2C%7B%22type%22:%22annotation%22%2C%22source%22:%22precomputed://gs://neuroglancer-janelia-flyem-hemibrain/v1.2/synapses%22%2C%22tab%22:%22rendering%22%2C%22ignoreNullSegmentFilter%22:false%2C%22shader%22:%22#uicontrol%20bool%20showPsds%20checkbox%28default=true%29%5Cn#uicontrol%20vec3%20preColor%20color%28default=%5C%22red%5C%22%29%5Cn#uicontrol%20vec3%20postColor%20color%28default=%5C%22blue%5C%22%29%5Cn#uicontrol%20float%20preConfidence%20slider%28min=0%2C%20max=1%2C%20default=0%29%5Cn#uicontrol%20float%20postConfidence%20slider%28min=0%2C%20max=1%2C%20default=0%29%5Cn%5Cnvoid%20main%28%29%20%7B%5Cn%20%20setColor%28defaultColor%28%29%29%3B%5Cn%20%20%5Cn%20%20setEndpointMarkerColor%28%5Cn%20%20%20%20vec4%28preColor%2C%200.5%29%2C%5Cn%20%20%20%20vec4%28postColor%2C%200.5%29%29%3B%5Cn%20%20%5Cn%20%20if%20%28showPsds%29%20%7B%5Cn%20%20%20%20setEndpointMarkerSize%288.0%2C%204.0%29%3B%5Cn%20%20%7D%5Cn%20%20else%20%7B%5Cn%20%20%20%20setLineWidth%280.0%29%3B%5Cn%20%20%20%20setEndpointMarkerSize%288.0%2C%200.0%29%3B%5Cn%20%20%7D%5Cn%20%20%5Cn%20%20if%20%28prop_pre_synaptic_confidence%28%29%3C%20preConfidence%20%7C%7C%5Cn%20%20%20%20%20%20prop_post_synaptic_confidence%28%29%3C%20postConfidence%29%20discard%3B%5Cn%7D%5Cn%22%2C%22shaderControls%22:%7B%22showPsds%22:false%7D%2C%22linkedSegmentationLayer%22:%7B%22pre_synaptic_cell%22:%22segmentation%22%2C%22post_synaptic_cell%22:%22segmentation%22%7D%2C%22filterBySegmentation%22:%5B%22pre_synaptic_cell%22%5D%2C%22name%22:%22synapse%22%2C%22visible%22:false%7D%2C%7B%22type%22:%22segmentation%22%2C%22source%22:%7B%22url%22:%22precomputed://gs://neuroglancer-janelia-flyem-hemibrain/v1.2/rois%22%2C%22subsources%22:%7B%22default%22:true%2C%22properties%22:true%2C%22mesh%22:true%7D%2C%22enableDefaultSubsources%22:false%7D%2C%22pick%22:false%2C%22tab%22:%22segments%22%2C%22selectedAlpha%22:0%2C%22saturation%22:0%2C%22objectAlpha%22:0.8%2C%22ignoreNullVisibleSet%22:false%2C%22meshSilhouetteRendering%22:3%2C%22segments%22:%5B%5D%2C%22name%22:%22roi%22%7D%2C%7B%22type%22:%22segmentation%22%2C%22source%22:%7B%22url%22:%22precomputed://gs://neuroglancer-janelia-flyem-hemibrain/v1.2/mito-classes%22%2C%22subsources%22:%7B%22default%22:true%2C%22properties%22:true%2C%22mesh%22:true%7D%2C%22enableDefaultSubsources%22:false%7D%2C%22pick%22:false%2C%22tab%22:%22segments%22%2C%22segments%22:%5B%5D%2C%22segmentColors%22:%7B%224%22:%22#000000%22%7D%2C%22name%22:%22mito-classes%22%2C%22visible%22:false%7D%2C%7B%22type%22:%22segmentation%22%2C%22source%22:%7B%22url%22:%22precomputed://gs://neuroglancer-janelia-flyem-hemibrain/mask_normalized_round6%22%2C%22subsources%22:%7B%22default%22:true%2C%22properties%22:true%7D%2C%22enableDefaultSubsources%22:false%7D%2C%22pick%22:false%2C%22tab%22:%22segments%22%2C%22selectedAlpha%22:0.53%2C%22segments%22:%5B%5D%2C%22segmentColors%22:%7B%227%22:%22#000000%22%7D%2C%22name%22:%22voxel-classes%22%2C%22visible%22:false%7D%2C%7B%22type%22:%22segmentation%22%2C%22source%22:%7B%22url%22:%22precomputed://gs://flyem-ng-layers/hemibrain/all_brain_roi%22%2C%22subsources%22:%7B%22default%22:true%2C%22properties%22:true%2C%22mesh%22:true%7D%2C%22enableDefaultSubsources%22:false%7D%2C%22pick%22:false%2C%22tab%22:%22source%22%2C%22selectedAlpha%22:0%2C%22saturation%22:0%2C%22meshSilhouetteRendering%22:4%2C%22segments%22:%5B%221%22%5D%2C%22name%22:%22brain-mask%22%2C%22visible%22:false%7D%5D%2C%22showSlices%22:false%2C%22selectedLayer%22:%7B%22visible%22:true%2C%22layer%22:%22segmentation%22%7D%2C%22layout%22:%22xy-3d%22%7D'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07e7a560-bb5c-4bf0-bee5-d67e93bb93a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import urllib\n",
    "\n",
    "def parse_nglink(link):\n",
    "    url_base, pseudo_json = link.split('#!')\n",
    "    pseudo_json = urllib.parse.unquote(pseudo_json)\n",
    "    data = json.loads(pseudo_json)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "57926bd2-d2ce-4190-adcd-a90e47040d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Click this link:\n",
      "http://localhost:37081/v/ac5f29e983ea7f6a2a4d156d8983a4b5c0f078bd/\n"
     ]
    }
   ],
   "source": [
    "# pip install neuroglancer\n",
    "from neuroglancer import set_server_bind_address, Viewer, CoordinateSpace, ImageLayer, SegmentationLayer, LocalVolume, ManagedLayer\n",
    "\n",
    "# Using 0.0.0.0 as your bind address is similar to 127.0.0.1,\n",
    "# except it allows you to access the server from other machines.\n",
    "set_server_bind_address('0.0.0.0')\n",
    "\n",
    "# Create a neuroglancer viewer which we'll open in our browser but control from Python.\n",
    "viewer = Viewer()\n",
    "viewer.set_state(parse_nglink(TEMPLATE_LINK))\n",
    "\n",
    "# If you're running this notebook on your own laptop, just use 'localhost' to access your neuroglancer viewer.\n",
    "url = 'http://localhost:' + viewer.get_viewer_url().split(':')[2]\n",
    "\n",
    "# If you're running on a remote host (such as a cluster node), use the machine name.\n",
    "#url = f'http://{os.uname().nodename}:' + viewer.get_viewer_url().split(':')[2]\n",
    "\n",
    "print(\"Click this link:\")\n",
    "print(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e1a59b7-7101-4559-923f-332d34d8b9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can bundle modifications of the viewer state\n",
    "# into a 'transaction' (txn) which will be applied all at once.\n",
    "with viewer.txn() as s:\n",
    "    s.position = c\n",
    "\n",
    "    # Create a neuroglancer layer to display the neuron mask we downloaded -- directly from our numpy array.\n",
    "    # This coordinate space is made for the hemibrain, which has resolution [8nm, 8nm, 8nm]\n",
    "    cspace = CoordinateSpace(names=[*'xyz'], units='nm', scales=[8,8,8])\n",
    "    local_vol = LocalVolume(neuron_mask.astype(np.uint8), cspace, 'segmentation', box[0])\n",
    "    s.layers['neuron-mask'] = ManagedLayer('neuron-mask', local_vol, segments=[1], objectAlpha=0.5)\n",
    "    \n",
    "    # Example: pre-configure the layer settings as you like.\n",
    "    s.layers['neuron-mask'].selectedAlpha = 0.5\n",
    "    s.layers['neuron-mask'].objectAlpha = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb257b4-8aa3-4d12-8525-e01c40546772",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
